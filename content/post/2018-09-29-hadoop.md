---
title: Hadoop搭建
author: ~
date: '2018-09-29'
slug: hadoop
categories: [Hadoop,linux]
tags: [Hadoop, spark]
---

# 小规模Spark集群搭建
> 此方法只适用于小规模机群搭建，对于大规模集群搭建，请学习脚本配置。本次搭建的服务器有六台，每台服务器的处理器为 **Intel(R) Core(TM) i5-3450 CPU @ 3.10GHz**，内存为8GB。服务器的静态IP为`166.111.17.69`，搭建底层系统为centos7.0

## centos7.0安装
1. 制作centos7.0 的光驱文件
2. 安装master服务器时注意需要安装图形界面，因为学校联网需要认证
3. 安装时，选择其他服务器时，选择安全工具和java平台
4. 需要设置网络，可以在开始安装时设置网络。网络配置文件在目录`/etc/sysconfig/net-work-scripts/`下，将DNS设置为`166.111.8.29`和`166.111.8.28`（学校DNS服务器），以及将`ONBOOT`设置为`on`
5. 网线连接，即可以进行配置

## Hadoop2.6.0搭建
### ssh登录免密码设置
以`root`的身份登录服务器，修改服务器的名称 

	nano /etc/hosts
	
修改配置文件

	166.111.17.69  master
	166.111.17.121 node1
	166.111.17.122 node2
	166.111.17.123 node3
	166.111.17.124 node4
	166.111.17.125 node5
	
在每一台服务器上添加名为hadoop用户

	useradd hadoop
	passwd hadoop
	
在master服务器上产生密钥对，将公共秘钥分配给其他服务器

	su hadoop
	ssh-keygen -t rsa
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@master
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node1
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node2
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node3
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node4
	ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node5
	
使认证文件不能被修改

	chmod 0600 ~/.ssh/authorized_keys
	
### JAVA安装
下载所需要的java版本到文件夹`/usr`下

	cd /usr
	wget http://javadl.sun.com/webapps/download/AutoDL?BundleId=114681
	
解压安装java文件，并转移到jdk文件夹下面

	tar -zxf jdk-8u65-linux-x64.tar.gz
	mv jdk1.8.0_65 jdk
	
下面将文件夹拷贝到其他节点

	scp -r jdk node1:/usr
	scp -r jdk node2:/usr
	scp -r jdk node3:/usr
	scp -r jdk node4:/usr
	scp -r jdk node5:/usr
	
在每一个节点上更改其默认的java路径

	alternatives -- install /usr/bin/java java /usr/jdk/bin/java 2
	alternatives --config java #select appropriate program (/usr/jdk/bin/java)
	alternatives  --install /usr/bin/jar jar /usr/jdk/bin/jar 2
	alternatives --install /usr/bin/javac javac /usr/jdk/bin/javac 2
	alternatives --set jar /usr/jdk/bin/jar
	alternatives --set javac /usr/jdk/bin/javac
	
修改环境变量

	nano /etc/bashrc
	
向其中文件加入下面的内容

	export JAVA_HOME=/usr/jdk
	export JRE_HOME=/usr/jdk/jre
	export PATH=$PATH:/usr/jdk/bin:/usr/jdk/jre/bin
	
也可以添加下面的内容，使文件更容易阅读

	alias ll='ls -l --color'
	alias cp='cp -i'
	alias mv='mv -i'
	alias rm='rm -i'
	
修改好文件之后，重新启动服务

	source /etc/bashrc
	echo $JAVA_HOME
	
这样子java环境也就配置好了

### 服务器时间同步
很多情况下，服务器的时间并不统一，这样子会造成很多问题，例如文件同步时无法分清哪一台服务器上的文件是最新的。因此，有必要对服务器的时间进行同步，通步使用的是ntp服务。首先安装ntp服务

	yum -y install ntp
	
启动ntp服务

	ntpdate pool.ntp.org
	
修改配置文件

	vi /etc/ntp.conf
	
往文件中添加下面的内容

	#please consider joining the pool
	server internalntpserver1 iburst
	server internalntpserver2 iburst
	server pool.ntp.org iburst
	
重新启动服务

	chkconfig ntpd on
	service ntpd start
	
安装过程可能导致时区的不一致，下面将时区统一

	timedatectl		#查看系统时间设置
	timedatectl list-timezones    #查看所有可选时区
	timedatectl set-timezones Asia/Shanghai   #统一设置成北京时间
	
### Hadoop2.6.0安装

从官网上下载到`/usr`下，运行下面的命令

	wget http://www.eu.apache.org/dist/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz
	
解压文件，并把文件转移到文件夹hadoop下

	tar -zxf hadoop-2.6.0.tar.gz
	rm hadoop-2.6.0.tar.gz
	mv hadoop-2.6.0 hadoop
	
修改文件`/usr/hadoop/etc/hadoop/core-site.xml`，设置Namenode的URI

	<configuration>
	<property>
    	<name>fs.defaultFS</name>
    	<value>hdfs://master:9000/</value>
	</property>
	</configuration>
	
修改文件`usr/hadoop/etc/hadoop/hdfs-site.xml`，设置DataNondes

	<configuration>
	<property>
  		<name>dfs.replication</name>
  		<value>3</value>
	</property>
	<property>
  		<name>dfs.permissions</name>
  		<value>false</value>
	</property>
	<property>
   		<name>dfs.datanode.data.dir</name>
   		<value>/home/hadoop/datanode</value>
	</property>
	</configuration>

修改文件`/usr/hadoop/etc/hadoop/yarn-site.xml`，设置资源管理者和节点管理者

	<configuration>
	<property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
	</property>
	<property>
        <name>yarn.nodemanager.hostname</name>
        <value>hmaster</value> <!-- or node1, node2, node3, node4, node5 -->
	</property>
	<property>
  		<name>yarn.nodemanager.aux-services</name>
    	<value>mapreduce_shuffle</value>
	</property>
	</configuration>

在所有节点上修改`/home/hadoop/.bashrc`

	vi /home/hadoop/.bashrc
	
向文件中添加西面的内容

	export HADOOP_PREFIX=/usr/hadoop
	export HADOOP_HOME=$HADOOP_PREFIX
	export HADOOP_COMMON_HOME=$HADOOP_PREFIX
	export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop
	export HADOOP_HDFS_HOME=$HADOOP_PREFIX
	export HADOOP_MAPRED_HOME=$HADOOP_PREFIX
	export HADOOP_YARN_HOME=$HADOOP_PREFIX
	export PATH=$PATH:$HADOOP_PREFIX/sbin:$HADOOP_PREFIX/bin
	
将hadoop文件拷贝到各个节点`/usr`目录下

	scp -r hadoop node1:/usr
	scp -r hadoop node2:/usr
	scp -r hadoop node3:/usr
	scp -r hadoop node4:/usr
	scp -r hadoop node5:/usr
	
将hadoop文件夹的权限赋予hadoop用户，以及创建datanode文件夹

	chown hadoop /usr/hadoop/ -R
	chgrp hadoop /usr/hadoop/ -R
	mkdir /home/hadoop/datanode
	chown hadoop /home/hadoop/datanode/
	chgrp hadoop /home/hadoop/datanode/  
	
配置master服务器上的文件`/usr/hadoop/etc/hadoop/hdfs-site.xml`

	<property>
        <name>dfs.namenode.data.dir</name>
        <value>/home/hadoop/namenode</value>
	</property>
	
配置master服务器上的文件`/usr/hadoop/etc/hadoop/mapred-site.xml`

	<configuration>
 	<property>
  		<name>mapreduce.framework.name</name>
   		<value>yarn</value> <!-- and not local (!) -->
 	</property>
	</configuration>
	
配置master服务器上的文件`/usr/hadoop/etc/hadoop/slaves`

	master
	node1
	node2
	node3
	node4
	node5
	
配置完成之后，输入下面的命令

	su hadoop
	hdfs namenode -format
	sh /usr/hadoop/sbin/start-all.sh
	
输入`jps`，即可查看状态

### Scala安装
从官网上下载安装文件
	
